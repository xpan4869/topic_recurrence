{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8330d13b",
   "metadata": {},
   "source": [
    "***Author:*** Yolanda Pan\n",
    "\n",
    "***Assignment Requrement:*** liteartures beyond ITR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d714dcc",
   "metadata": {},
   "source": [
    "***Rearch Question:*** How do topic content and topic dynamics in first-time conversations shape perceived enjoyment and social connection?\n",
    "\n",
    "Potential Angels:\n",
    "\n",
    "1) a semantic network of conversations, and \n",
    "\n",
    "2) a dynamic topic–shift model to reveal theoretical gaps about conversational flow, exploration policies, and relationship formation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184a1cc",
   "metadata": {},
   "source": [
    "## 5 Psychology References from the past 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95148b08",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Wald, K. A., Kardas, M., & Epley, N. (2024). Misplaced Divides? Discussing Political Disagreement With Strangers Can Be Unexpectedly Positive. Psychological Science, 35(5), 471-488. https://doi.org/10.1177/09567976241230005</font>\n",
    "\n",
    "Wald, Kardas, & Epley (2024) investigate why people avoid political conversations with those who disagree, despite social and democratic benefits. Experiment 1 (N = 450) shows that people expect disagreement conversations to be far less positive (M = 3.37 vs. 6.89; ηp² = .50), more awkward, and more avoidable (ηp² = .11). Experiment 2 (N = 198) reveals that these expectations are miscalibrated: although participants forecast large differences between agreement and disagreement (ηp² = .22), their actual experiences did not differ (ηp² = .02), and miscalibration was largest in disagreement (d = –1.80). Participants also underestimated how much similarity would emerge (d = –1.69). Experiment 3 (N = 216) demonstrates that people mispredict because they overemphasize partner agreement (ηp² = .24) and underestimate the affiliative power of dialogue; disagreement conversations were equally positive in real-time conversation but significantly less positive in monologue (d = 1.18). Overall, the studies show that people systematically overestimate the negativity of political disagreement conversations, leading to unnecessary avoidance and missed opportunities for connection and learning.\n",
    "\n",
    "My project extends this foundation by using the CANDOR dataset, which contains longer, naturalistic, multi-turn dyadic conversations rather than short, experimenter-prompted discussions. Although the CANDOR data do not permit a direct test of miscalibration (because we lack participants’ pre-conversation predictions), we may observe the moments when conversational partners take interpersonal risks—such as shifting into sensitive topics—and analyze how those risks unfold in real time. By examining both the structural position of these risky topics within the semantic network of the conversation and their temporal position in the interaction, we can identify when and how people choose to take such risks, and whether the timing or sequencing of these moves predicts conversational outcomes such as enjoyment or rapport."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c57f69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d8ad9",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Kardas, M., Kumar, A., & Epley, N. (2022). Overly shallow?: Miscalibrated expectations create a barrier to deeper conversation. Journal of Personality and Social Psychology, 122(3), 367–398.</font>\n",
    "\n",
    "Kardas, Kumar, and Epley (2022) investigate why people rarely engage in deeper, more intimate conversations despite wanting more meaningful social connection. Through seven experiments with ~1,800 participants, this study showed that deep, intimate conversation topics (personal vulnerabilities, meaningful experiences) between strangers lead to higher enjoyment and connectedness than trivial “small talk” topics. Participants consistently underestimated how much they and their partners would enjoy deeper topics – expecting awkwardness that never materialized\n",
    "\n",
    "However, all conversations were brief (often ~10–15 minutes) and topic depth was mostly manipulated by prompts, which may not capture naturally emerging topics. Also, participants were aware they were in an experiment, potentially reducing truly aversive topics.\n",
    "\n",
    "My project builds on and extends this foundation by shifting from laboratory-based choice paradigms to naturalistic, dyadic conversations from the CANDOR corpus. Rather than examining hypothetical or prompted topic preferences, I analyze how participants actually move into and through deeper conversation topics, and whether these choices predict downstream social outcomes like enjoyment. Hypothetically, I may find a consistency in topic choices as significant predictors of enjoyment. This would provide naturalistic behavioral evidence supporting Kardas et al.’s central claim: that deeper topics are not just theoretically better, but measurably so in real-world interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc01e83",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bab2d4",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Leckfor, C. M., Wood, N. R., Slatcher, R. B., & Orehek, E. (2025). Not such fast friends? The effect of intimate conversation on social connection in text-based getting acquainted interactions. Journal of Social and Personal Relationships, 42(11), 3272-3294.</font>\n",
    "\n",
    "This experiment assigned 286 stranger pairs to have either “intimate” (deep self-disclosure) or small-talk conversations, either face-to-face or via texting. **Intimate topics (reciprocal personal disclosures) led to greater felt closeness and connection than small talk, regardless of medium.** Face-to-face interaction fostered more self-disclosure than texting, but notably text-based deep chats still boosted connection – people can bond over intimate topics even in texts. However, the study focused on one-time, short interactions; long-term relationship formation wasn’t observed. Also, text conversations had lower overall disclosure, suggesting medium effects that weren’t fully controlled beyond self-report mediation.\n",
    "\n",
    "My project extends this work by examining how conversational depth emerges spontaneously in CANDOR’s large corpus of dyadic spoken interactions. Rather than relying on experimental prompts, I use topic modeling and semantic labeling to identify naturally occurring personal and identity-relevant themes (e.g., trauma, family, beliefs, goals [ideally]). I then test whether certain semantic topic categories—particularly those related to sensitive or emotionally significant areas—predict variation in conversation quality measures.\n",
    "\n",
    "Although certain abstract psychological features may be difficult to detect computationally at scale, coarse topic categories offer a tractable way to capture meaningful variation in conversational depth. Furthermore, CANDOR includes self-reported measures of self- and partner-disclosure (i_disclosed, you_disclosed), which provide a valuable bridge between subjective experience and objective content. By linking topical content with disclosure ratings and social outcomes, my project aims to clarify not only whether intimacy enhances connection, but which types of intimate topics are most socially effective—and under what conditions (e.g., reciprocated vs. one-sided). This offers a concrete extension of Leckfor et al.’s findings into naturalistic, unscripted conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba64dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836606fe",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Speer, S. P. H., Mwilambwe-Tshilobo, L., Tsoi, L., Burns, S. M., Falk, E. B., & Tamir, D. I. (2024). Hyperscanning shows friends explore and strangers converge in conversation. Nature Communications, 15(1), 7781. https://doi.org/10.1038/s41467-024-51990-7</font>\n",
    "\n",
    "Using fMRI hyperscanning and linguistic analysis, this study found that friends naturally “explore new ground” – their brain patterns and language diverge as they introduce diverse, novel topics – whereas strangers tend to “find common ground” – their neural and linguistic patterns converge on shared topics. Crucially, for strangers, conversations that more closely resembled the friends’ exploratory pattern (i.e. covering novel, surprising topics rather than just safe commonalities) were more enjoyable. This highlights topic novelty and breadth as keys to a fulfilling interaction. However, the conversations were semi-structured with prompt questions, and the sample (60 dyads) may have limited diversity. Also, measuring enjoyment via self-report post-scan might miss nuances during the conversation.\n",
    "\n",
    "My project will address this gap by focusing on the temporal dynamics of topic content in naturalistic, dyadic conversations using the CANDOR corpus. Rather than prompting depth, I observe how participants organically move into deeper content areas, such as family, trauma, identity, or values. Using topic modeling and semantic segmentation, I trace how conversations evolve across time—identifying topic shifts, escalation into personal domains, and whether conversational depth emerges abruptly or gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce03eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdf3ce",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Welker, C., Wheatley, T., Cason, G., Gorman, C., & Meyer, M. (2024). Self-views converge during enjoyable conversations. Proceedings of the National Academy of Sciences, 121(43), e2321652121.</font>\n",
    "\n",
    "In a round-robin lab study, unacquainted individuals conversed and rated their own personality traits before and after. The researchers found that one 10-minute conversation can align partners’ self-perceptions (“inter-self alignment”) and that greater alignment in self-views predicted higher enjoyment and desire to meet again. **They manipulated topic depth (deep vs. shallow prompts) expecting deeper talks to produce more alignment, but interestingly both casual and deep conversations produced similar alignment and enjoyment effects.** This suggests even light topics, through dialogue, can create a shared understanding that people enjoy.\n",
    "\n",
    "However, the sample was college students, and conversations were limited in time and context (lab prompts), which might not generalize to all populations or longer interactions. Also, the measure of content “depth” was coarse; they didn’t analyze specific topic features beyond the prompt type.\n",
    "\n",
    "Our goal is to extend these findings from controlled settings to natural conversations: we ask whether semantic alignment – i.e. alignment in the content and themes of what is said – emerging dynamically during a dialogue similarly predicts partners’ enjoyment and sense of connection. Using the CANDOR corpus of unstructured dyadic chats, we can explore how strangers naturally build common ground and whether increasing convergence of semantic content over time is associated with feeling closer, liking each other more, and enjoying the conversation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b327416",
   "metadata": {},
   "source": [
    "**Thoughts**\n",
    "\n",
    "Building on work showing that deep or intimate topics enhance closeness (Kardas et al.; Leckfor et al.), and evidence from CANDOR that fast turn-taking and engaged backchanneling predict enjoyment, we hypothesize that:\n",
    "\n",
    "H1: Topic depth will positively predict conversational enjoyment only when responsiveness (e.g., rapid turn-taking, backchannel frequency) is high.\n",
    "When responsiveness is low, deep topics will not reliably increase enjoyment. When responsiveness is low, deep topics will not reliably increase enjoyment.\n",
    "\n",
    "Speer et al. show novelty promotes neural synchrony, while Welker et al. and CANDOR show that alignment, not depth, predicts enjoyment. Therefore:\n",
    "\n",
    "H2: Semantic novelty in a speaker’s turn will increase partner enjoyment only when it is followed by subsequent semantic alignment (e.g., convergence in embeddings). Novelty without alignment will not enhance conversational outcomes.\n",
    "\n",
    "Research on miscalibration (Wald et al.) suggests people overestimate awkwardness, yet risky topics often produce positive outcomes once rapport exists. Thus:\n",
    "\n",
    "H3: The introduction of sensitive or intimate topics will increase partner enjoyment only when preceded by micro-alignment (e.g., matching affect, shared self-views, semantic convergence). Sensitive topics introduced early or without alignment will yield weaker effects.\n",
    "\n",
    "CANDOR shows conversations evolve dynamically and that trajectory (not static depth) predicts quality. Therefore:\n",
    "\n",
    "H4: Increases over time in semantic alignment, emotional expressiveness, and/or calibrated novelty will positively predict conversational enjoyment, independent of topic category. Flat or declining trajectories will predict lower enjoyment even in conversations with deep topics.\n",
    "\n",
    "Supporting Welker et al. and CANDOR’s semantic convergence results:\n",
    "\n",
    "H5: Shallow topics will produce enjoyment comparable to deep topics when they generate alignment (e.g., shared self-views, semantic similarity, parallel emotional expressions). Thus, shallow content can be functionally “deep” when used to build shared meaning.\n",
    "\n",
    "Synthesizing across the literature, we expect:\n",
    "\n",
    "H6: A model including all five conversational processes—risk-taking, novelty, alignment, responsiveness, and temporal trajectory—will outperform models based solely on topic depth or topic category in predicting conversational enjoyment. This hypothesis tests the core proposition that processual dynamics, not topic labels, best explain connection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398b0e7",
   "metadata": {},
   "source": [
    "## 5 Data Mining References from the past 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665696d5",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Hughes, M., Roy, B., Poole-Dayan, E., Roy, D., & Kabbara, J. (2025, November). Computational Analysis of Conversation Dynamics through Participant Responsivity. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (pp. 35500-35519).</font>\n",
    "\n",
    "This paper introduces **responsivity**—the extent to which a conversational turn responds to an earlier one—as a core metric for assessing the quality of **multi-party dialogue**. The authors argue that constructive communication relies not only on the absence of toxicity but on meaningful, reciprocal engagement. Using 262 **facilitated dialogues** from the Fora dataset, they evaluate two automated annotation methods: (1) **semantic similarity** via **MPNet embeddings** *('for a given turn, we compute its cosine similarity to the preceding 10 turns, and form a responsivity links to those turns with responsivity above a threshold')*, and (2) a **three-stage large language model (LLM) pipeline** *(turn-level linking → segment alignment → mechanical vs. substantive classification)*. **Human-annotated** conversations serve as ground truth.\n",
    "\n",
    "LLMs (GPT-4o and Claude 3.5) considerably outperform semantic similarity in capturing human-like responsivity links. The LLMs also classify substantive vs. mechanical responsivity with high agreement to human labels, revealing that substantive responses frequently follow personal stories rather than opinion statements. The paper provides detailed evaluation using Jaccard similarity, showing LLM–human alignment comparable to human–human variation, highlighting the inherent subjectivity of the task.\n",
    "\n",
    "The authors derive 23 conversation-level metrics, including speaking-time inequality (Gini), turn-sequence entropy, substantive responsivity rates, and distributional measures of who responds to whom. Using UMAP + HDBSCAN clustering, they identify five conversation types, such as “Participant-Driven, Substantively Engaged Dialogues” and “Structured, Unequal, Large-Group Conversations.” These clusters align with known distinctions between dialogue formats, such as citizen assemblies, youth discussions, and conversation-based games.\n",
    "\n",
    "The work advances computational dialogue analysis by shifting focus from toxic content detection to prosocial interaction structure. Responsivity is shown to be a foundational marker of constructive discourse, providing new avenues for analyzing deliberative democracy, facilitated dialogue, and online conversation platforms. The LLM-based method offers a scalable approach for mapping conversational networks and evaluating engagement quality.\n",
    "\n",
    "Human annotators still disagree substantially; semantic similarity models fail to capture nuanced relational dynamics; and LLM-based judgments may embed biases. Future work aims to integrate additional signals of healthy dialogue, such as storytelling and idea introduction, and to develop participant-level taxonomies of communication behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995be518",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8b698",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Xing, L., & Carenini, G. (2021). Improving unsupervised dialogue topic segmentation with utterance-pair coherence scoring. arXiv preprint arXiv:2106.06719.</font>\n",
    "\n",
    "This paper introduced an unsupervised topic segmentation method for dialogues that goes beyond simple lexical similarity. The authors trained a BERT-based utterance coherence model to score how topically connected two utterances are, then used those scores to decide segmentation boundaries. This significantly outperformed prior state-of-the-art segmentation on multiple datasets, demonstrating that injecting a learned notion of coherence can better detect where topics change in multi-turn dialogue. \n",
    "\n",
    "Limitations: The approach still relies on a synthetic training procedure to generate “positive” vs. “negative” utterance pairs for coherence, which might not capture all nuances of real conversation shifts. It also doesn’t incorporate speaker intentions or world knowledge – it’s purely text-based, so it might miss subtle topic shifts that aren’t obvious from surface words. Use in CANDOR: This method is highly relevant to my project’s goal of modeling topic shifts. I could adopt their coherence-scoring idea to help build CANDOR’s semantic network: e.g. using a similar BERT-based metric to decide when a new node (topic) in the network should be created (i.e. a topic boundary) based on utterance similarity. Extension: By doing so, my work adapts an NLP technique to a new context – rather than segmenting a transcript offline, I would integrate it into an ongoing model of the conversation’s semantic trajectory. This extends their work by linking it to conversational outcomes: I can examine if segments identified by high coherence yield higher enjoyment or smoother interactions (filling a gap between pure segmentation and social dynamics). New or Adapted Method?: This would be an adaptation rather than a novel method – I’m leveraging their unsupervised segmentation approach within CANDOR. However, I might need to extend it (e.g. incorporate speaker role information or fine-tune it on dyadic conversation data) to suit my specific domain of stranger conversations. In summary, Xing & Carenini give me a solid starting algorithm for detecting topic shifts, which I will build upon and possibly augment with CANDOR’s network perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c63ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28adc4",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Wohltjen, Sophie, and Thalia Wheatley. “Eye Contact Marks the Rise and Fall of Shared Attention in Conversation.” Proceedings of the National Academy of Sciences 118, no. 37 (2021): e2106645118. https://doi.org/10.1073/pnas.2106645118.</font>\n",
    "\n",
    "This study demonstrates that eye contact acts as a dynamic marker of shared attention during spontaneous conversation. Using dual eye-tracking, the authors show that moments of mutual gaze do not simply coordinate turn-taking—they synchronize neural and attentional states, correspond to peaks in mutual engagement, and organize the ebb and flow of conversational alignment.\n",
    "\n",
    "Wohltjen & Wheatley provide strong evidence that interpersonal coordination in conversation is rhythmic and adaptive, consistent with theories from dynamical systems and social neuroscience. This work complements emerging findings that the quality of a conversation depends on flexible, not constant, synchrony—a theme also present in contemporary research on semantic synchrony and pink-noise dynamics.\n",
    "\n",
    "This brought us to question how do conversational partners move in and out of coordination—and how does this predict enjoyment, connection, and conversation quality? One potential is to observe how nonverbal behavioral synchrony predict enjoyment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64cd70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756cac86",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Wang, H., Li, P., Fan, Y., & Zhu, Q. (2025, January). Simulating Dual-Process Thinking in Dialogue Topic Shift Detection. In Proceedings of the 31st International Conference on Computational Linguistics (pp. 2592-2602).</font>\n",
    "\n",
    "Main Contribution: This work introduces a Dual-Module Framework (DMF) for detecting topic shifts, inspired by Kahneman’s dual-process theory. The model has a fast, intuitive module (System 1) that quickly matches the current utterance with past context (to catch abrupt changes), and a slower, reasoning module (System 2) that uses a broader historical structure and chain-of-thought (CoT) reasoning to confirm a topic shift. By emulating human intuition and analysis, their approach achieved higher accuracy (F1) than baseline models on multiple datasets, especially improving detection of the actual “shift” points (which are relatively rare and often missed by simpler models). Limitations: The model is more complex and computationally heavy, combining large language model reasoning with fine-tuned components. It requires labeled data for training and CoT fine-tuning, and its performance, while improved, still showed that “shift” instances are much harder to identify (class imbalance issues remain). Also, as a research prototype, it’s unclear how it handles very long conversations or generalizes to informal, messy dialogues beyond the tested corpora. Use in CANDOR: The idea of merging local cues and global context is valuable for my research. I can draw on their approach by, for example, designing CANDOR’s topic shift detector to first flag potential shifts via a lightweight similarity check (local intuition) and then validate those using a more holistic semantic network context (global reasoning). Essentially, I’d be adapting their dual-process strategy: quick detection of a possible shift when the conversation’s semantic network graph shows a sudden introduction of unrelated concepts, followed by a more thorough check using the broader conversation context stored in the network. Extension: My work would extend DMF by incorporating network-based reasoning – instead of just sequential text analysis, the “reasoning module” could examine the semantic network (clusters of related topics discussed so far) to decide if a new utterance truly represents a departure into a new topic cluster. This would be a novel twist, filling a gap because current models don’t leverage graph-based conversation memory. New or Adapted Method?: This is a hybrid approach: I’m adapting the dual-process concept (from cognitive theory to algorithm design) and injecting a new element (semantic network memory from CANDOR). It’s not building a completely new model from scratch – it stands on the shoulders of Wang et al.’s architecture – but it innovates by using a different knowledge representation (network of topics) for the reasoning step. This cross-pollination of ideas would result in a method that can detect topic shifts more robustly and also link those shifts to conversational quality (e.g. detecting if abrupt shifts derail enjoyment, connecting back to the social angle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c34ae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b77a63",
   "metadata": {},
   "source": [
    "<font color='darkblue'>Lee, S., Yoo, Y., Jung, M., & Song, M. (2025). Def-DTS: Deductive Reasoning for Open-domain Dialogue Topic Segmentation. arXiv preprint arXiv:2505.21033.</font>\n",
    "\n",
    "\n",
    "Main Contribution: This paper tackles topic segmentation with the power of large language models (LLMs). The authors propose Def-DTS, a multi-step prompting approach where an LLM is guided through a deductive reasoning process: it summarizes the prior context, infers each utterance’s intent, and then decides if a topic shift occurs. By breaking the task into structured sub-tasks (bidirectional context summarization, intent classification, then shift detection), they imbue the model with a form of reasoning. Results: Def-DTS outperformed both unsupervised and prior supervised methods on several open-domain and task-oriented dialogue datasets. Notably, it reduced segmentation errors and improved true positive detection of topic changes, illustrating the promise of LLM reasoning in dialogue understanding. \n",
    "\n",
    "Limitations: Using LLMs (likely GPT-3.5 or similar) for segmentation is computationally expensive and may not be feasible for real-time analysis or very long conversations. There’s also a dependency on prompt quality – the method might be sensitive to how the prompts are written, and it could struggle with domain-specific language unless prompts are adapted. Moreover, while the approach is “open-domain,” it’s constrained by the LLM’s knowledge cutoff and may not handle conversations with very novel jargon or erratic structure. \n",
    "\n",
    "Use in CANDOR: The idea of deductive, multi-step reasoning aligns with how I envision modeling conversations in CANDOR. I likely won’t deploy a huge LLM in real time for each conversation, but I can adapt the structured reasoning approach: for example, have components in my system that (a) summarize recent dialogue context (building a subgraph of recent topics), (b) classify the intent or topic of the new utterance (maybe using a smaller transformer or classifier trained on conversation data), and (c) decide if we’ve hit a new topic node in the semantic network. This draws on Def-DTS’s strategy but tailors it to a network-based, possibly more lightweight implementation. Extending or New?: In essence, I’d be borrowing the decomposition logic (summarize -> interpret -> segment) from Lee et al., but implementing it in a new way within a semantic network framework, possibly with a domain-specific model. That means it’s an adaptation of a method from a different domain (LLM reasoning) to my domain of semantic networks. Additionally, Def-DTS doesn’t explicitly connect topic shifts to social outcomes – it’s purely about accuracy. My work would extend it by examining how these segmented topics relate to things like enjoyment or engagement, thereby filling a gap between pure NLP segmentation and the interpersonal, theoretical questions (e.g., do certain types of topic shifts correspond to drops or boosts in rapport?). Social-Theoretical Gap: By incorporating a deductive topic modeling approach, I can explore if applying such segmentation reveals patterns like “conversations that smoothly follow a logical topic trajectory (as Def-DTS would enforce) are more enjoyable.” This connects an advanced computational method back to the social theory of conversation quality – a link that prior computational papers have not made, and which my research aims to solidify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9b2d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
